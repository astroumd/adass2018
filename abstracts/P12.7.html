<!-- generic header for adass web pages -->
<!DOCTYPE html>
<html lang="en">

    <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>ADASS 2018 | Abstracts</title>

    <!-- Bootstrap core CSS -->
    <link href="/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="/css/modern-business.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Carrois+Gothic+SC" rel="stylesheet"> 
    </head>

    <body>

        <!--#include virtual="/includes/nav_p.inc"-->

        <!-- Page Content -->
        <div class="container">
        <br>
        <div id="poster">
        <h2 style="padding-top: 80px; margin-top: -80px;">
        <ol class="breadcrumb">
        <li class="breadcrumb-item">
        Abstracts
        </li>    
        </ol>
        </h2>
Prev: <a href="/abstracts/P4.9.html">P4.9</a> Next: <a href="/abstracts/P12.8.html">P12.8</a> <br><br>
<b>P12.7: Kaplan, Kyle</b>
<br>
Kyle F. Kaplan (University of Arizona) <br>   <br>   <br>   <br>   <br>  <br><br>
<br>
<b>Theme:</b>  Algorithms
<br>
<b>Title:</b> <i>The algorithms behind the HPF and NEID pipeline</i>
<br><p>
Abstract: HPF and NEID are new high-resolution stabilized echelle spectrometers at the forefront of using radial velocity techniques to search for terrestrial mass exoplanets.  Nightly data taken at the telescopes with large format detectors must be automatically processed into radial velocities in less than 24 hours.  This requires a large investment in computer power and memory along with an automated pipeline that can check the quality of the data and handle issues without the need for human intervention.  I will present an overview of our pipeline and discuss the, sometimes novel, algorithms and techniques we use to turn the unprocessed 2D echellograms into optimally extracted 1D spectra.   These algorithms include the use of polygon clipping to rectify the curvature found in the beams on the detectors, the ability to fully account for aliasing in under-sampled data on the detector using flat lamp spectra, and the use of pixel count histograms to automatically match similar exposures and check the quality of the data.  I will also discuss how our pipeline is built up from many independent modules, making it robust against failure and allowing it to be easily modifiable.</p>
</div><!-- id -->
<!--#include virtual="/includes/footer.inc" -->

    <!-- Bootstrap core JavaScript -->
    <script src="/vendor/jquery/jquery.min.js"></script>
    <script src="/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  </body>

</html>

                                                            
